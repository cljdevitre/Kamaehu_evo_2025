{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import DiadFit as pf\n",
    "import mineralML as mm\n",
    "import Thermobar as pt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we concatenate all the EDS data by type (standards, olivines, MIglasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading Oct15th.xlsx: Worksheet named 'Glass_Data' not found\n",
      "Error reading Oct4th.xlsx: Worksheet named 'Glass_Data' not found\n",
      "Error reading Oct1718th.xlsx: Worksheet named 'Glass_Data' not found\n",
      "Error reading Oct25th.xlsx: Worksheet named 'Glass_Data' not found\n",
      "Error reading R3_June1824_modDec0624.xlsx: Worksheet named 'Glass_Data' not found\n",
      "Data has been concatenated and exported to /Users/cljd/pCloud Drive/WORK-GENERAL/POSTDOC-UCB/BERKELEY-VIBE/Documents/Projects/Kamaehu2024/2large4GIT/EDS/Processed_data/concatenated_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.getcwd()  # Set the folder path to the current working directory\n",
    "\n",
    "# Create dictionaries to hold DataFrames for each sheet type\n",
    "standards_dict = {}\n",
    "olivines_dict = {}\n",
    "glasses_dict = {}\n",
    "\n",
    "# Define the sheet names\n",
    "sheet_names = {\n",
    "    'Standards': 'Standards',\n",
    "    'Olivine_Data': 'Olivine_Data',\n",
    "    'Glass_Data': 'Glass_Data'\n",
    "}\n",
    "\n",
    "# Loop through all files in the specified folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.xlsx') or filename.endswith('.xls'):\n",
    "        if \"concatenated\" not in filename:\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                # Read each sheet into the corresponding DataFrame\n",
    "                for key, sheet_name in sheet_names.items():\n",
    "                    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "                    # Drop columns with \"Unnamed\" in their header\n",
    "                    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "                    \n",
    "                    # Store the DataFrame in the corresponding dictionary\n",
    "                    if key == 'Standards':\n",
    "                        standards_dict[os.path.splitext(filename)[0]] = df\n",
    "                    elif key == 'Olivine_Data':\n",
    "                        olivines_dict[os.path.splitext(filename)[0]] = df\n",
    "                    elif key == 'Glass_Data':\n",
    "                        glasses_dict[os.path.splitext(filename)[0]] = df\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames in each dictionary\n",
    "concatenated_standards = pd.concat(standards_dict.values(), axis=0, join='outer')\n",
    "concatenated_olivines = pd.concat(olivines_dict.values(), axis=0, join='outer')\n",
    "concatenated_glasses = pd.concat(glasses_dict.values(), axis=0, join='outer')\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = os.path.join(folder_path, 'concatenated_data.xlsx')\n",
    "\n",
    "# Use ExcelWriter to export multiple sheets to a single Excel file\n",
    "with pd.ExcelWriter(output_file_path) as writer:\n",
    "    concatenated_standards.to_excel(writer, sheet_name='concatenated_standards', index=False)\n",
    "    concatenated_olivines.to_excel(writer, sheet_name='concatenated_olivines', index=False)\n",
    "    concatenated_glasses.to_excel(writer, sheet_name='concatenated_glasses', index=False)\n",
    "\n",
    "print(f\"Data has been concatenated and exported to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## run through minml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py3124/lib/python3.12/site-packages/mineralML/core.py:285: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  check_point = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "df_final=pt.minClass(pd.read_excel(\"concatenated_data.xlsx\",sheet_name='concatenated_olivines'))\n",
    "df_final.to_clipboard(excel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you prefer separate files one by one use this below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = os.getcwd()  # Set the folder path to the current working directory\n",
    "standards_dict = {}\n",
    "# sheet_name='Standards'\n",
    "sheet_name='Olivine_Data'\n",
    "# sheet_name='Glass_Data'\n",
    "\n",
    "\n",
    "# Loop through all files in the specified folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.xlsx') or filename.endswith('.xls'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            # Read the \"Standards\" sheet into a DataFrame\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "            # Drop columns with \"Unnamed\" in their header\n",
    "            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "            # Store the DataFrame in the dictionary using the filename (without extension) as the key\n",
    "            standards_dict[os.path.splitext(filename)[0]] = df\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames in the dictionary\n",
    "concatenated_df = pd.concat(standards_dict.values(), axis=0, join='outer')\n",
    "\n",
    "output_file_path = os.path.join(folder_path, 'concatenated_olivines.xlsx')\n",
    "concatenated_df.to_excel(output_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3115",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
